# If the policy learning failed, insert a new procedural subgoal before the current goal to perform the given subtask
sp {retrospective-learning*propose*add-node-to-goal-graph*learning*failure
   (state <s> ^name retrospective-learning
              ^policy-learning-result failure
              ^subtask-episode <ep>)
   (<ep> ^task-stack.bottom <bot-seg>)
   (<bot-seg> ^task-operator.subtask-handle <sub-h>
              ^prev <par-seg>)
   (<par-seg> ^task-operator <task-op>
              ^current-goal.handle <goal-h>)
   (<task-op> ^task-handle <task-h>)
-->
   (<s> ^operator <o> + >)
   (<o> ^name add-node-to-goal-graph
        ^type subtask
        ^task-handle <task-h>
        ^subtask-handle <sub-h>
        ^original-goal-handle <goal-h>)
}

# before <goal-h>: the handle of the goal we are going to push a procedural goal in front of
#   If there is a handle substitution, use the substituted version
sp {retrospective-learning*elaborate*add-node-to-goal-graph*before*substitute
   (state <s> ^name retrospective-learning
              ^operator <o> +
              ^goal-handle-subs.<goal-h> <sub-h>)
   (<o> ^name add-node-to-goal-graph
        ^type subtask
        ^original-goal-handle <goal-h>)
-->
   (<o> ^before <sub-h>)
}

# Otherwise just use the original goal handle
sp {retrospective-learning*elaborate*add-node-to-goal-graph*original-goal-handle
   (state <s> ^name retrospective-learning
              ^operator <o> +
              ^goal-handle-subs <subs>)
   (<o> ^name add-node-to-goal-graph
        ^type subtask
        ^original-goal-handle <goal-h>)
   (<subs> -^<goal-h> <sub-h>)
-->
   (<o> ^before <goal-h>)
}


###
# Operator No-Change Substate: will create the procedural subgoal, add it to the goal-graph, 
#                              and return its handle as added-procedural-subgoal <sub-h>
###

# when we added the procedural subgoal, try to learn the policy again by removing the failure flag
sp {retrospective-learning*apply*add-node-to-goal-graph*remove*failure
   (state <s> ^name retrospective-learning
              ^operator <o>
              ^policy-learning-result failure)
   (<o> ^name add-node-to-goal-graph
        ^add-node-result <node-h>)
-->
   (<s> ^policy-learning-result failure -)
}

sp {retrospective-learning*apply*add-node-to-goal-graph*mark*goal-handle*substitution
   (state <s> ^name retrospective-learning
              ^operator <o>
              ^goal-handle-subs <subs>)
   (<o> ^name add-node-to-goal-graph
        ^type subtask
        ^original-goal-handle <goal-h>
        ^add-node-result <node-h>)
-->
   (<subs> ^<goal-h> <node-h>)
}

sp {retrospective-learning*apply*add-node-to-goal-graph*remove*goal-handle*substitution*prev
   (state <s> ^name retrospective-learning
              ^operator <o>
              ^goal-handle-subs <subs>)
   (<o> ^name add-node-to-goal-graph
        ^type subtask
        ^original-goal-handle <goal-h>
        ^add-node-result <node-h>)
   (<subs> ^<goal-h> { <old-h> <> <node-h> })
-->
   (<subs> ^<goal-h> <old-h> -)
}
